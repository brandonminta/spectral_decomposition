{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decc3d47-0e2f-455f-9a17-f82b5df34101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from spectral_cube import SpectralCube\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04aa00a-ecd0-410f-af5d-a18954d76a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norma_askap = pd.read_pickle('RESULTS/norma_askap.pkl')\n",
    "df_hydra_askap = pd.read_pickle('RESULTS/hydra_askap.pkl')\n",
    "df_normaV2_atca = pd.read_pickle('RESULTS/norma_atca_0.2kms.pkl')\n",
    "df_norma4k_atca = pd.read_pickle('RESULTS/norma_atca_4kms.pkl')\n",
    "df_hydraV2_atca = pd.read_pickle('RESULTS/hydra_atca_0.2kms.pkl')\n",
    "df_hydra4k_atca = pd.read_pickle('RESULTS/hydra_atca_4kms.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26eae1-1110-4574-899a-fc797ff7d4d0",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc621f3f-5655-4495-9477-740e211c38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_sources(df1, df2):\n",
    "    # Round 'ra (deg)' and 'dec (deg)' columns to 2 decimal places\n",
    "    df1_rounded = df1.copy()\n",
    "    df2_rounded = df2.copy()\n",
    "    \n",
    "    df1_rounded['ra (deg)'] = df1_rounded['ra (deg)'].round(2)\n",
    "    df1_rounded['dec (deg)'] = df1_rounded['dec (deg)'].round(2)\n",
    "    \n",
    "    df2_rounded['ra (deg)'] = df2_rounded['ra (deg)'].round(2)\n",
    "    df2_rounded['dec (deg)'] = df2_rounded['dec (deg)'].round(2)\n",
    "    \n",
    "    # Merge on 'ra (deg)' and 'dec (deg)'\n",
    "    merged_df = pd.merge(df1_rounded, df2_rounded, \n",
    "                         on=['ra (deg)', 'dec (deg)'], \n",
    "                         suffixes=('_df1', '_df2'), \n",
    "                         how='inner')\n",
    "    \n",
    "    # Return the tuple of matched 'source' columns from both DataFrames\n",
    "    return list(zip(merged_df['source_df1'], merged_df['source_df2']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f452b6-2cab-47a0-9f42-c85770e67ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate a single Gaussian component\n",
    "def gaussian(x, amplitude, mean, stddev):\n",
    "    return amplitude * np.exp(-0.5 * ((x - mean) / stddev)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725a1560-cb30-435f-b38b-e568c5f0b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_calculation(velocity, amplitude):\n",
    "        # Measure variability (RMS)\n",
    "    rms_spect = np.sqrt(np.mean(amplitude**2))\n",
    "    \n",
    "    # Mask signal channels\n",
    "    spectrum = np.copy(amplitude)\n",
    "    spectrum[spectrum < rms_spect - (np.max(spectrum) - rms_spect)] = rms_spect\n",
    "    \n",
    "    # Normalization\n",
    "    y = spectrum\n",
    "    x = velocity\n",
    "    pars = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(pars)\n",
    "    tauhi = np.array(amplitude / p(x))\n",
    "    \n",
    "    # Calculate tau\n",
    "    return np.log(tauhi) * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05b36c3-1f49-42af-b456-f4479d983dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_spectra(file_pairs, region, df_1, df_2, df_3,save_as_pdf=False, pdf_filename='test.pdf'):\n",
    "    # Base directories for the ASKAP and ATCA files\n",
    "    askap_dir = f'ASKAP_spectra/{region}/'\n",
    "    atca_dir = f'ATCA_HI_spectra/{region}/'\n",
    "    \n",
    "    # If saving as PDF, create a PdfPages object\n",
    "    if save_as_pdf:\n",
    "        pdf = PdfPages(pdf_filename)\n",
    "    \n",
    "    # Loop over each file pair (tuple) in the list\n",
    "    for askap_file, atca_file in file_pairs:\n",
    "        # Construct the full paths for the ASKAP and ATCA files\n",
    "        askap_path = os.path.join(askap_dir, f'{askap_file}_askap_spectrum.txt')\n",
    "        atca_path = os.path.join(atca_dir, f'{atca_file}_cube_4k_atca_4k_spectrum.txt')\n",
    "        atca_path_v2 = os.path.join(atca_dir, f'{atca_file}_cube_v2_atca_spectrum.txt')  # New path for ATCA v2\n",
    "\n",
    "        source_df_1 = df_1[df_1['source'] == askap_file]\n",
    "        source_df_2 = df_2[df_2['source'] == atca_file]\n",
    "        source_df_3 = df_3[df_3['source'] == atca_file]\n",
    "\n",
    "        # Load the ASKAP data\n",
    "        askap_data = np.loadtxt(askap_path, skiprows=1)\n",
    "        askap_velocity = askap_data[:, 1]  # velocity column\n",
    "        askap_amplitude = askap_data[:, 2]  # amplitude column\n",
    "        askap_amplitude = tau_calculation(askap_velocity, askap_amplitude)\n",
    "\n",
    "        # Load the ATCA data\n",
    "        atca_data = np.loadtxt(atca_path, skiprows=1)\n",
    "        atca_velocity = atca_data[:, 1]  # velocity column\n",
    "        atca_amplitude = atca_data[:, 2]  # amplitude column\n",
    "        atca_amplitude = tau_calculation(atca_velocity, atca_amplitude)\n",
    "\n",
    "        # Check if the third file (v2) exists\n",
    "        v2_exists = os.path.exists(atca_path_v2)\n",
    "\n",
    "        if v2_exists:\n",
    "            atca_data_v2 = np.loadtxt(atca_path_v2, skiprows=1)\n",
    "            atca_velocity_v2 = atca_data_v2[:, 1]  # velocity column\n",
    "            atca_amplitude_v2 = atca_data_v2[:, 2]  # amplitude column\n",
    "            atca_amplitude_v2 = tau_calculation(atca_velocity_v2, atca_amplitude_v2)\n",
    "\n",
    "            # Create the plot with three panels\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 9))  # Add a third panel\n",
    "        else:\n",
    "            # Create the plot with two panels if the third file doesn't exist\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "        # Plot each Gaussian component and the total fit in the upper panel (ax1)\n",
    "        total_fit_1 = np.zeros_like(askap_velocity)\n",
    "        ncomps1 = 0\n",
    "        for _, row in source_df_1.iterrows():\n",
    "            amplitude_1, mean_1, vel_disp_1 = row['amp'], row['VLSR'], row['vel_disp']\n",
    "            stddev_1 = vel_disp_1  # Assuming vel_disp is the velocity dispersion (σ)\n",
    "            total_fit_1 += gaussian(askap_velocity, amplitude_1, mean_1, stddev_1)\n",
    "            ncomps1 += 1\n",
    "            ax1.plot(askap_velocity, gaussian(askap_velocity, amplitude_1, mean_1, stddev_1), linestyle='-', lw=0.8, color='red')\n",
    "\n",
    "        # Plot for ASKAP data\n",
    "        ax1.plot(askap_velocity, askap_amplitude, label=f'ASKAP: {askap_file}', color='k', lw=0.8)\n",
    "        ax1.plot(askap_velocity, total_fit_1, color='r', lw=1.5)\n",
    "        ax1.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "        ax1.set_xlim(-150, 150)\n",
    "        ax1.set_ylabel(r'$\\tau$')\n",
    "        ax1.set_title(f'ASKAP Spectrum - {askap_file}' r'$\\quad N_{comp}=$' f'{ncomps1}')\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Plot each Gaussian component and the total fit in the second panel (ax2)\n",
    "        total_fit_2 = np.zeros_like(atca_velocity)\n",
    "        ncomps2 = 0\n",
    "        for _, row in source_df_2.iterrows():\n",
    "            amplitude_2, mean_2, vel_disp_2 = row['amp'], row['VLSR'], row['vel_disp']\n",
    "            stddev_2 = vel_disp_2\n",
    "            total_fit_2 += gaussian(atca_velocity, amplitude_2, mean_2, stddev_2)\n",
    "            ncomps2 += 1\n",
    "            ax2.plot(atca_velocity, gaussian(atca_velocity, amplitude_2, mean_2, stddev_2), linestyle='-', lw=0.8, color='red')\n",
    "\n",
    "        # Plot for ATCA data\n",
    "        ax2.plot(atca_velocity, atca_amplitude, label=f'ATCA: {atca_file}', color='k', lw=0.8)\n",
    "        ax2.plot(atca_velocity, total_fit_2, color='r', lw=1.5)\n",
    "        ax2.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "        ax2.set_xlim(-150, 150)\n",
    "        ax2.set_xlabel('Velocity (km/s)')\n",
    "        ax2.set_ylabel(r'$\\tau$')\n",
    "        ax2.set_title(f'ATCA Spectrum - {atca_file}' r'$\\quad N_{comp}=$' f'{ncomps2}')\n",
    "        ax2.grid(True)\n",
    "\n",
    "        # If the v2 file exists, plot it in the third panel\n",
    "        if v2_exists:\n",
    "            total_fit_3 = np.zeros_like(atca_velocity_v2)\n",
    "            ncomps3 = 0\n",
    "            for _, row in source_df_3.iterrows():\n",
    "                amplitude_3, mean_3, vel_disp_3 = row['amp'], row['VLSR'], row['vel_disp']\n",
    "                stddev_3 = vel_disp_3\n",
    "                total_fit_3 += gaussian(atca_velocity_v2, amplitude_3, mean_3, stddev_3)\n",
    "                ncomps3 += 1\n",
    "                ax3.plot(atca_velocity_v2, gaussian(atca_velocity_v2, amplitude_3, mean_3, stddev_3), linestyle='-', lw=0.8, color='red')\n",
    "            ax3.plot(atca_velocity_v2, atca_amplitude_v2, label=f'ATCA v2: {atca_file}', color='k', lw=0.8)\n",
    "            ax3.plot(atca_velocity_v2, total_fit_3, color='r', lw=1.5)\n",
    "            ax3.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "            ax3.set_xlim(-150, 150)\n",
    "            ax3.set_xlabel('Velocity (km/s)')\n",
    "            ax3.set_ylabel(r'$\\tau$')\n",
    "            ax3.set_title(f'ATCA v2 Spectrum - {atca_file}' r'$\\quad N_{comp}=$' f'{ncomps3}')\n",
    "            ax3.grid(True)\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        if save_as_pdf:\n",
    "            pdf.savefig(fig)  # Save the current figure to the PDF\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "        plt.close(fig)\n",
    "\n",
    "    # Close the PdfPages object if saving as PDF\n",
    "    if save_as_pdf:\n",
    "        pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b86269-de9a-4fe9-91b0-4f47249600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_data(file_path, y_pixel, x_pixel):\n",
    "    \"\"\"\n",
    "    Function to extract the spectral axis (x) and amplitude (spectrum) for a given pixel.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the FITS file.\n",
    "    y_pixel (int): The y-coordinate (spatial) in the cube.\n",
    "    x_pixel (int): The x-coordinate (spatial) in the cube.\n",
    "\n",
    "    Returns:\n",
    "    x (numpy array): The spectral axis (e.g., velocity in km/s).\n",
    "    amplitudes (numpy array): The spectrum (amplitude values) for the given pixel.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the cube using SpectralCube\n",
    "    cube = SpectralCube.read(file_path)\n",
    "    \n",
    "    # Extract the spectral axis (velocity in km/s)\n",
    "    x = cube.spectral_axis.value  # The x-axis, typically in km/s\n",
    "\n",
    "    # Extract the amplitude (spectrum) for the specific pixel (y_pixel, x_pixel)\n",
    "    amplitudes = cube.unmasked_data[:, y_pixel, x_pixel]\n",
    "    \n",
    "    return x, amplitudes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53fe5d90-548e-43b4-83ef-84ff2a49b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from astropy.convolution import convolve, Gaussian1DKernel\n",
    "\n",
    "def process_spectrum(file_path, gkernel):\n",
    "    # Load data from the file, skipping the first row\n",
    "    data = np.loadtxt(file_path, skiprows=1)\n",
    "\n",
    "    # Extract velocity and amplitude columns\n",
    "    velocity = data[:, 1]\n",
    "    amplitude = data[:, 2]\n",
    "    \n",
    "    # Measure variability (RMS)\n",
    "    rms_spect = np.sqrt(np.mean(amplitude**2))\n",
    "    \n",
    "    # Mask signal channels\n",
    "    spectrum = np.copy(amplitude)\n",
    "    spectrum[spectrum < rms_spect - (np.max(spectrum) - rms_spect)] = rms_spect\n",
    "    \n",
    "    # Normalization\n",
    "    y = spectrum\n",
    "    x = velocity\n",
    "    pars = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(pars)\n",
    "    tauhi = np.array(amplitude / p(x))\n",
    "    \n",
    "    # Calculate tau\n",
    "    tau = np.log(tauhi) * (-1)\n",
    "    rms = np.std(tau)\n",
    "    \n",
    "    # Smoothing with Gaussian Kernel\n",
    "    g = Gaussian1DKernel(gkernel)\n",
    "    tau_smooth = convolve(tau, g, boundary='extend')\n",
    "    \n",
    "    return tau_smooth, x\n",
    "\n",
    "def process_files_by_common_name(directory, common_name, common_name2 = None, direcotry2 = None, gkernel_4k=1., gkernel_v2=1.,):\n",
    "    # Search for files that start with the common name in the given directory\n",
    "    \n",
    "    files = [f for f in os.listdir(directory) if f.startswith(common_name) and f.endswith(\".txt\")]\n",
    "    if common_name2 is not None:\n",
    "        files2 = [f for f in os.listdir(directory2) if f.startswith(common_name2) and f.endswith(\".txt\")]\n",
    "    #if len(files) != 2:\n",
    "     #   raise ValueError(f\"Expected 2 files with common name '{common_name}', but found {len(files)}.\")\n",
    "    \n",
    "    file_4k = None\n",
    "    file_v2 = None\n",
    "    \n",
    "    # Determine which file corresponds to _cube_4k and which to _v2\n",
    "    for file in files:\n",
    "        if '_cube_4k' in file:\n",
    "            file_4k = os.path.join(directory, file)\n",
    "            if directory2 is None:\n",
    "                file_v2 = os.path.join(directory, file)\n",
    "    if files2 is not None:\n",
    "        for file in files2:\n",
    "            file_v2 = os.path.join(directory2, file)\n",
    "    \n",
    "    if file_4k is None or file_v2 is None:\n",
    "        raise ValueError(\"Could not find both _cube_4k and _v2 files.\")\n",
    "    \n",
    "    # Process the files\n",
    "    tau_smooth_4k, x_4k = process_spectrum(file_4k, gkernel_4k)\n",
    "    tau_smooth_v2, x_v2 = process_spectrum(file_v2, gkernel_v2)\n",
    "    \n",
    "    return tau_smooth_4k, x_4k, tau_smooth_v2, x_v2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f4cd0b-f978-499f-9948-067b8c5db4dc",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d7d576-0507-4ad7-9ab4-6671f32d5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_common_norma = match_sources(df_norma_askap, df_norma4k_atca)\n",
    "list_common_norma = list(set(list_common_norma))\n",
    "\n",
    "list_common_hydra = match_sources(df_hydra_askap, df_hydra4k_atca)\n",
    "list_common_hydra = list(set(list_common_hydra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f878dbf-ff09-4782-9aa4-e3fe1113876d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7245/3439610195.py:17: RuntimeWarning: invalid value encountered in log\n",
      "  return np.log(tauhi) * (-1)\n"
     ]
    }
   ],
   "source": [
    "plot_spectra(\n",
    "    list_common_norma, \n",
    "    'Norma',\n",
    "    df_norma_askap, \n",
    "    df_norma4k_atca,\n",
    "    df_normaV2_atca, \n",
    "    save_as_pdf = True,\n",
    "    pdf_filename='norma_field.pdf')  # Specify 'Norma' or 'Hydra' as the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a6dd65e-6fb9-4fbe-bcc3-b3f42ab55695",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectra(\n",
    "    list_common_hydra, \n",
    "    'Hydra',\n",
    "    df_hydra_askap, \n",
    "    df_hydra4k_atca,\n",
    "    df_hydraV2_atca, \n",
    "    save_as_pdf = True,\n",
    "    pdf_filename='hydra_field.pdf')  # Specify 'Norma' or 'Hydra' as the region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad609c9-55a2-403d-b2f0-58ea69b41452",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924ec9e-2804-475d-b824-5dd8a933874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_spectra(directory, common_sources, df_1, df_2, output_pdf, direcotry2=None):\n",
    "    # Calculate the number of rows and columns for subplots\n",
    "    num_files = len(common_sources)\n",
    "    num_rows = int(np.ceil(num_files / 3))  # 3 subplots per row\n",
    "    # Create a single figure with multiple subplots\n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(18, 8*num_rows))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "    # Iterate through matching files and create subplots for each file\n",
    "    for i, common_name in enumerate(common_sources):\n",
    "        source_df_1 = df_1[df_1['source_new'] == common_name]\n",
    "        source_df_2 = df_2[df_2['source_new'] == common_name]\n",
    "        common_name = df_1.loc[df_1['source_new'] == common_name, 'source'].values[0]\n",
    "        common_name2 = df_2.loc[df_2['source_new'] == common_name, 'source'].values[0] \n",
    "\n",
    "        tau_1, x_1, tau_2, x_2 = process_files_by_common_name(directory, common_name, common_name2, directory2)\n",
    "        # Read data from the text file into a NumPy array, skipping the header row\n",
    "        \n",
    "        # Create a nested grid within each subplot\n",
    "        outer_ax = axes[i]\n",
    "        gs = outer_ax.get_gridspec()\n",
    "        outer_ax.remove()\n",
    "\n",
    "        inner_gs = gs[i].subgridspec(2, 1, height_ratios=[1, 1], hspace=0.28)\n",
    "        ax1 = fig.add_subplot(inner_gs[0])\n",
    "        ax2 = fig.add_subplot(inner_gs[1])\n",
    "\n",
    "        # Initialize an array to hold the total fit\n",
    "        total_fit_1 = np.zeros_like(x_1)\n",
    "        \n",
    "        # Plot each Gaussian component and the total fit in the lower panel (ax2)\n",
    "        ncomps1 = 0\n",
    "        for _, row in source_df_1.iterrows():\n",
    "            amplitude_1, mean_1, vel_disp_1 = row['amp'], row['VLSR'], row['vel_disp']\n",
    "            stddev_1 = vel_disp_1  # Assuming vel_disp is the velocity dispersion (σ)\n",
    "            total_fit_1 += gaussian(x_1, amplitude_1, mean_1, stddev_1)\n",
    "            ncomps1 += 1\n",
    "            ax1.plot(x_1, gaussian(x_1, amplitude_1, mean_1, stddev_1), linestyle='-', lw=0.8, color = 'red')\n",
    "    \n",
    "        # Plot the total fit in the lower panel (ax2)\n",
    "        ax1.plot(x_1, tau_1, color='k', label='Original Spectrum', lw=0.8)\n",
    "        ax1.plot(x_1, total_fit_1, color='red', label='Total Fit', lw=1.2)\n",
    "        ax1.set_xlabel('Velocity (km/s)')\n",
    "        ax1.set_ylabel('Amplitude')\n",
    "        ax1.set_title(f'{common_name} - ATCA ' r'$\\quad N_{comp}=$' f'{ncomps1}')\n",
    "        #ax1.set_xlim(-150,150)\n",
    "        # Initialize an array to hold the total fit\n",
    "        total_fit_2 = np.zeros_like(x_2)\n",
    "        \n",
    "        # Plot each Gaussian component and the total fit in the lower panel (ax2)\n",
    "        ncomps2 = 0\n",
    "        for _, row in source_df_2.iterrows():\n",
    "            amplitude_2, mean_2, vel_disp_2 = row['amp'], row['VLSR'], row['vel_disp']\n",
    "            stddev_2 = vel_disp_2  # Assuming vel_disp is the velocity dispersion (σ)\n",
    "            total_fit_2 += gaussian(x_2, amplitude_2, mean_2, stddev_2)\n",
    "            ncomps2+=1\n",
    "            ax2.plot(x_2, gaussian(x_2, amplitude_2, mean_2, stddev_2), linestyle='-', color='red', lw=0.8)\n",
    "    \n",
    "        # Plot the total fit in the lower panel (ax2)\n",
    "        ax2.plot(x_2, tau_2, color='k', label='Original Spectrum', lw=0.8)\n",
    "        ax2.plot(x_2, total_fit_2, color='red', label='Total Fit', lw=1.2)\n",
    "        ax2.set_xlabel('Velocity (km/s)')\n",
    "        ax2.set_ylabel('Amplitude')\n",
    "        ax2.set_title(f'{common_name} - ASKAP ' r'$\\quad N_{comp}=$' f'{ncomps2}')\n",
    "        ax2.set_xlim(-200,300)\n",
    "        # Title for the overall plot area\n",
    "        #outer_ax.set_title(f'File: {file_name}')\n",
    "\n",
    "    # Hide any remaining empty subplots, if any\n",
    "    for j in range(num_files, num_rows * 3):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Adjust layout and display the figure\n",
    "    plt.tight_layout()\n",
    "    if output_pdf is not None:\n",
    "        plt.savefig(f'{output_pdf}.pdf', format='pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68b509-6c84-4de0-be65-5d8876da86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract the 'source' column from both DataFrames\n",
    "sources_df1 = set(df_norma4k_atca['source'])\n",
    "sources_df2 = set(df_normaV2_atca['source'])\n",
    "\n",
    "# 2. Find the common sources between the two DataFrames\n",
    "common_sources = sources_df1.intersection(sources_df2)\n",
    "\n",
    "# 3. Display the common sources\n",
    "print(\"Common source names:\", common_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2a5ca-1922-4cf7-b0e7-b281c94a2e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "directory = 'ATCA_HI_spectra/Norma/'\n",
    "output_pdf = 'norma_atca_gaussian_decompositions.pdf'\n",
    "\n",
    "plot_all_spectra(directory, common_sources, df_norma4k_atca, df_normaV2_atca,  output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72b4fa-c7e4-448a-a724-4ae56bc032ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract the 'source' column from both DataFrames\n",
    "sources_df1 = set(df_hydra4k_atca['source'])\n",
    "sources_df2 = set(df_hydraV2_atca['source'])\n",
    "\n",
    "# 2. Find the common sources between the two DataFrames\n",
    "common_sources = sources_df1.intersection(sources_df2)\n",
    "\n",
    "# 3. Display the common sources\n",
    "print(\"Common source names:\", common_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76990056-5056-4216-a7b7-153d3877c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "directory = 'ATCA_HI_spectra/Hydra/'\n",
    "output_pdf = 'hydra_atca_gaussian_decompositions.pdf'\n",
    "\n",
    "plot_all_spectra(directory, common_sources, df_hydra4k_atca, df_hydraV2_atca,  output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ed38b-3f2a-4260-b5ab-4ee567096eb8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. Extract the 'source' column from both DataFrames\n",
    "sources_df1 = set(df_hydra4k_atca['source'])\n",
    "sources_df2 = set(df_hydra_askap['source'])\n",
    "def normalize_source_format(source):\n",
    "    \"\"\"\n",
    "    Normalize source format by removing the 'j' if present and truncating to match the desired format.\n",
    "    \"\"\"\n",
    "    if source.startswith('j'):\n",
    "        # Remove the 'j' and truncate to four decimal places\n",
    "        return source[0:7] + '-' + source[8:13]\n",
    "    else:\n",
    "        # Remove decimal points and truncate to four decimal places\n",
    "        return 'j'+ source[:6] + '-' + source[9:-2]\n",
    "\n",
    "# 1. Normalize the 'source' column from both DataFrames\n",
    "normalized_sources_df1 = {normalize_source_format(source) for source in sources_df1}\n",
    "normalized_sources_df2 = {normalize_source_format(source) for source in sources_df2}\n",
    "# 2. Find the common sources between the two DataFrames\n",
    "common_sources = normalized_sources_df1.intersection(normalized_sources_df2)\n",
    "\n",
    "# 3. Display the common sources\n",
    "print(\"Common source names:\", common_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa938d3-ab03-4101-bd55-16adcb3dc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_hydra_askap is your DataFrame\n",
    "df_hydra_askap['source_new'] = df_hydra_askap['source'].apply(lambda source: 'j' + source[:6] + '-' + source[9:-2])\n",
    "df_hydra4k_atca['source_new'] = df_hydra4k_atca['source'].apply(lambda source: source[0:7] + '-' + source[8:13])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e6697-367e-4541-ad12-7f5f84519e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract the 'source' column from both DataFrames\n",
    "sources_df1 = set(df_hydra4k_atca['source_new'])\n",
    "sources_df2 = set(df_hydra_askap['source_new'])\n",
    "\n",
    "# 2. Find the common sources between the two DataFrames\n",
    "common_sources = sources_df1.intersection(sources_df2)\n",
    "\n",
    "# 3. Display the common sources\n",
    "print(\"Common source names:\", common_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119db71-d9ce-44d5-a4d1-9dced285d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "directory = 'ATCA_HI_spectra/Hydra/'\n",
    "directory2 = 'ASKAP_spectra/Hydra/'\n",
    "output_pdf = 'hydra_gaussian_decompositions.pdf'\n",
    "\n",
    "plot_all_spectra(directory, common_sources, df_hydra4k_atca, df_hydra_askap,  output_pdf, directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09913c2f-2cab-4e25-8b2e-a14236cc3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_hydra_askap is your DataFrame\n",
    "df_norma_askap['source_new'] = df_norma_askap['source'].apply(lambda source: 'j' + source[:6] + '-' + source[9:-2])\n",
    "df_norma4k_atca['source_new'] = df_norma4k_atca['source'].apply(lambda source: source[0:7] + '-' + source[8:13])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1289cd-bc65-4368-974a-582f1944cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract the 'source' column from both DataFrames\n",
    "sources_df1 = set(df_norma4k_atca['source_new'])\n",
    "sources_df2 = set(df_norma_askap['source_new'])\n",
    "\n",
    "# 2. Find the common sources between the two DataFrames\n",
    "common_sources = sources_df1.intersection(sources_df2)\n",
    "\n",
    "# 3. Display the common sources\n",
    "print(\"Common source names:\", common_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b6eea-2432-4199-9119-289c171c7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "directory = 'ATCA_HI_spectra/Norma/'\n",
    "directory2 = 'ASKAP_spectra/Norma/'\n",
    "output_pdf = 'norma_gaussian_decompositions.pdf'\n",
    "\n",
    "plot_all_spectra(directory, common_sources, df_norma4k_atca, df_norma_askap,  output_pdf, directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c4ab3-f3dd-4377-9e7b-2ea03896e0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
